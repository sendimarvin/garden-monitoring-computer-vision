{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f21f95",
   "metadata": {},
   "source": [
    "# Naive Bayes Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3db2de",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df4179d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from skimage import exposure\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import shift\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def pad_array(arr, n):\n",
    "    #if len(arr) >= n:\n",
    "        #return arr[:n]  # Trim the array if it's longer than n\n",
    "    #else:\n",
    "    pad_width = (0, n - len(arr))  # Calculate the padding width\n",
    "    return np.pad(arr, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def rgb2gray(image):\n",
    "    return np.dot(image[..., :3], [0.2989, 0.587, 0.114])\n",
    "\n",
    "def sobel_filter(image):\n",
    "    ## Standard Sobel\n",
    "    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "    ## Customer kernel\n",
    "#     kernel_x = np.array([[0, 0, 0], [1, 0, -1], [0, 0, 0]])\n",
    "#     kernel_y = np.array([[0, 1, 0], [0, 0, 0], [0, -1, 0]])\n",
    "    \n",
    "    gradient_x = convolve2d(image, kernel_x)\n",
    "    gradient_y = convolve2d(image, kernel_y)\n",
    "    \n",
    "    edge_features = np.sqrt(gradient_x ** 2 + gradient_y ** 2)\n",
    "    return edge_features\n",
    "\n",
    "def sharpen_image(image, strength=1):\n",
    "    # Create a Laplacian kernel for image sharpening\n",
    "    kernel = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n",
    "    \n",
    "    # Apply the convolution operation using the Laplacian kernel\n",
    "    sharpened_image = image + strength * convolve(image, kernel)\n",
    "    \n",
    "    # Clip the pixel values to ensure they are within the valid range\n",
    "    sharpened_image = np.clip(sharpened_image, 0, 255)\n",
    "    \n",
    "    return sharpened_image\n",
    "\n",
    "def emboss_image(image):\n",
    "    kernel = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n",
    "    \n",
    "    # Apply the convolution operation using the emboss kernel\n",
    "    embossed_image = convolve(image, kernel)\n",
    "    \n",
    "    # Clip the pixel values to ensure they are within the valid range\n",
    "    embossed_image = np.clip(embossed_image, 0, 255)\n",
    "    \n",
    "    return embossed_image\n",
    "\n",
    "def gaussian_filter(image, sigma=1):\n",
    "    size = int(2 * np.ceil(3 * sigma) + 1)  # Filter size\n",
    "    kernel = gaussian_kernel(size, sigma)  # Generate the Gaussian kernel\n",
    "    \n",
    "    # Apply the convolution operation using the Gaussian kernel\n",
    "    filtered_image = convolve(image, kernel)\n",
    "    \n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def gaussian_kernel(size, sigma):\n",
    "    kernel = np.fromfunction(lambda x, y: gaussian(x, y, size, sigma), (size, size))\n",
    "    kernel /= np.sum(kernel)  # Normalize the kernel\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def gaussian(x, y, size, sigma):\n",
    "    center = size // 2\n",
    "    exponent = -((x - center) ** 2 + (y - center) ** 2) / (2 * sigma ** 2)\n",
    "    return (1 / (2 * np.pi * sigma ** 2)) * np.exp(exponent)\n",
    "\n",
    "def convolve2d(image, kernel):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    padding = kernel_size // 2\n",
    "    \n",
    "    image_padded = np.pad(image, padding, mode='constant')\n",
    "    height, width = image.shape\n",
    "    \n",
    "    output = np.zeros_like(image)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            patch = image_padded[i:i+kernel_size, j:j+kernel_size]\n",
    "            output[i, j] = np.sum(patch * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def calculate_histogram(image):\n",
    "    hist = np.zeros(256)\n",
    "    height, width = image.shape\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            intensity = image[i, j]\n",
    "            hist[intensity] += 1\n",
    "    \n",
    "    return hist\n",
    "\n",
    "\n",
    "def calculate_glcm(image):\n",
    "    glcm = np.zeros((256, 256))\n",
    "    height, width = image.shape\n",
    "\n",
    "    for i in range(height - 1):\n",
    "        for j in range(width - 1):\n",
    "            intensity1 = image[i, j]\n",
    "            intensity2 = image[i, j + 1]\n",
    "            glcm[intensity1, intensity2] += 1\n",
    "            glcm[intensity2, intensity1] += 1  # Add the symmetric entry\n",
    "    \n",
    "    glcm /= np.sum(glcm)\n",
    "    return glcm\n",
    "\n",
    "def calculate_contrast(glcm):\n",
    "    contrast = 0\n",
    "    for i in range(glcm.shape[0]):\n",
    "        for j in range(glcm.shape[1]):\n",
    "            contrast += glcm[i, j] * (i - j) ** 2\n",
    "    return contrast\n",
    "\n",
    "def calculate_energy(glcm):\n",
    "    energy = np.sum(glcm ** 2)\n",
    "    return energy\n",
    "\n",
    "\n",
    "def calculate_correlation(glcm):\n",
    "    row_mean = np.mean(glcm, axis=1, keepdims=True)\n",
    "    col_mean = np.mean(glcm, axis=0, keepdims=True)\n",
    "    row_std = np.std(glcm, axis=1, ddof=1, keepdims=True)\n",
    "    col_std = np.std(glcm, axis=0, ddof=1, keepdims=True)\n",
    "    \n",
    "    correlation = np.sum((glcm - row_mean) * (glcm - col_mean)) / (row_std * col_std)\n",
    "    return correlation\n",
    "\n",
    "def extract_features(image, output_folder, file_name):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = rgb2gray(image)\n",
    "    \n",
    "    gray_image1 = gray_image\n",
    "    \n",
    "    # Convert the image to unsigned integer type\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Save the grayscale image\n",
    "    grayscale_path = os.path.join(output_folder, file_name+'grayscale.png')\n",
    "    plt.imsave(grayscale_path, gray_image1, cmap='gray')\n",
    "    \n",
    "    # Extract edge features using Sobel filter\n",
    "    edge_features = sobel_filter(gray_image1)    \n",
    "    \n",
    "    # Save the edge features image\n",
    "    edge_path = os.path.join(output_folder, file_name+'edge_features.png')\n",
    "    plt.imsave(edge_path, edge_features, cmap='gray')\n",
    "    \n",
    "    # Extract sharpened features using Sobel filter\n",
    "    sharpened_features = sharpen_image(gray_image1, 2)\n",
    "    \n",
    "    # Save the sharpened features image\n",
    "    sharpened_path = os.path.join(output_folder, file_name+'sharpened_features.png')\n",
    "    plt.imsave(sharpened_path, sharpened_features, cmap='gray')\n",
    "    \n",
    "    \n",
    "    # Extract emboss features using filter\n",
    "    emboss_features = emboss_image(gray_image1)\n",
    "    \n",
    "    # Save the emboss features image\n",
    "    emboss_path = os.path.join(output_folder, file_name+'emboss_features.png')\n",
    "    plt.imsave(emboss_path, emboss_features, cmap='gray')\n",
    "    \n",
    "    # Extract Gaussian features using filter\n",
    "    gaussian_features = gaussian_filter(gray_image1)\n",
    "    \n",
    "    # Save the gaussian features image\n",
    "    gaussian_path = os.path.join(output_folder, file_name+'gaussian_features.png')\n",
    "    plt.imsave(gaussian_path, gaussian_features, cmap='gray')\n",
    "    \n",
    "    # Calculate histogram features\n",
    "    hist = calculate_histogram(gray_image)\n",
    "    \n",
    "    # Calculate texture features using GLCM (Grey-Level Co-occurrence Matrix)\n",
    "    glcm = calculate_glcm(gray_image)\n",
    "    contrast = calculate_contrast(glcm)\n",
    "    energy = calculate_energy(glcm)\n",
    "    correlation = calculate_correlation(glcm)\n",
    "\n",
    "    # Save the histogram features plot\n",
    "    hist_path = os.path.join(output_folder, file_name+'histogram.png')\n",
    "    plt.plot(hist)\n",
    "    plt.xlabel('Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(hist_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Concatenate all features into a single feature vector\n",
    "    #features = np.concatenate([edge_features.flatten(), gaussian_features.flatten(), sharpened_features.flatten(), emboss_features.flatten(), hist, [contrast, energy, correlation]])\n",
    "    features = np.concatenate([edge_features.flatten(), sharpened_features.flatten(), emboss_features.flatten(), hist])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e16f3",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96d0ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the image folders\n",
    "folder_path = '../deeplearning-model/data/known_images/'\n",
    "output_folder = '../deeplearning-model/data/known_images_out/'\n",
    "\n",
    "# Set the target image size\n",
    "target_size = (256, 256)  # Adjust this as needed\n",
    "\n",
    "# Load the image data and labels\n",
    "X = []\n",
    "y = []\n",
    "class_labels = ['cassava', 'maize', 'banana', 'weed']\n",
    "#class_labels=['x']\n",
    "for label in class_labels:\n",
    "    folder = os.path.join(folder_path, label)\n",
    "    images = os.listdir(folder)\n",
    "    for image_file in images:\n",
    "        img_path = os.path.join(folder, image_file)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')  # Convert to RGB if needed\n",
    "        img = img.resize(target_size)  # Resize the image\n",
    "                \n",
    "        # Extract the features from the image\n",
    "        img_features = extract_features(np.array(img), output_folder, label+image_file)\n",
    "        flattened_img_features = pad_array(img_features.flatten(), 250000)\n",
    "        \n",
    "        #print(len(flattened_img_features))\n",
    "        \n",
    "        #img_array = np.array(img)\n",
    "        #X.append(img_array.flatten())  # Flatten the image to a 1D vector\n",
    "        X.append(flattened_img_features)\n",
    "        y.append(label)\n",
    "        #break\n",
    "    #break\n",
    "\n",
    "# Convert data to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8009166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 250000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c55e5ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the Naive Bayes classifier\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#model.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Predict the labels for the test set\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:267\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    266\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:426\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    425\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[1;32m--> 426\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[1;32m-> 1104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    875\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 877\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    881\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py:83\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray\u001b[39m(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert the input to an array.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "#y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba885a2",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report = classification_report(y_test, y_pred, zero_division=1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae71a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9ff93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
